# ğŸ¯ V3: The Official Pipecat Way

## What Makes V3 Different?

V3 is a **complete rewrite** following the [Official Pipecat Quickstart Guide](https://docs.pipecat.ai/getting-started/quickstart). This isn't just about using Pipecatâ€”it's about using it **the right way**.

---

## The Pipecat Philosophy

### 1. **Runner System**

**Official Pattern:**
```python
async def bot(runner_args: RunnerArguments):
    """Entry point that runner system calls"""
    transport = await create_transport(runner_args, params)
    await run_bot(transport, runner_args)

if __name__ == "__main__":
    from pipecat.runner.run import main
    main()  # â† Official runner
```

**What This Gives You:**
- âœ… Automatic CLI argument parsing
- âœ… Environment handling
- âœ… Signal management (Ctrl+C)
- âœ… Transport setup/teardown
- âœ… Production deployment compatibility

### 2. **Transport Layer**

**Official Pattern:**
```python
transport_params = {
    "daily": lambda: DailyParams(
        audio_in_enabled=True,
        audio_out_enabled=True,
        vad_analyzer=SileroVADAnalyzer(),
    ),
}

transport = await create_transport(runner_args, transport_params)
```

**What This Gives You:**
- âœ… WebRTC with proper ICE/STUN/TURN
- âœ… Server-side Voice Activity Detection
- âœ… Real-time bidirectional audio
- âœ… Automatic reconnection
- âœ… Built-in Daily.co integration

### 3. **Context Aggregators**

**Official Pattern:**
```python
context = OpenAILLMContext(messages=messages)
context_aggregator = llm.create_context_aggregator(context)

pipeline = Pipeline([
    transport.input(),
    stt,
    context_aggregator.user(),      # â† Auto-adds user message
    llm,
    tts,
    context_aggregator.assistant(), # â† Auto-adds bot response
    transport.output(),
])
```

**What This Gives You:**
- âœ… Automatic conversation tracking
- âœ… No manual `context.add_message()`
- âœ… Proper message ordering
- âœ… Built-in error handling

### 4. **Event Handlers**

**Official Pattern:**
```python
@transport.event_handler("on_client_connected")
async def on_client_connected(transport, client):
    logger.info("Client connected")
    await task.queue_frames([LLMRunFrame()])

@transport.event_handler("on_client_disconnected")
async def on_client_disconnected(transport, client):
    logger.info("Client disconnected")
    await task.cancel()
```

**What This Gives You:**
- âœ… Clean lifecycle management
- âœ… Proper resource cleanup
- âœ… Easy to add new events
- âœ… Matches Pipecat docs exactly

### 5. **RTVI Protocol**

**Official Pattern:**
```python
rtvi = RTVIProcessor(config=RTVIConfig(config=[]))

task = PipelineTask(
    pipeline,
    params=PipelineParams(
        enable_metrics=True,
        enable_usage_metrics=True,
    ),
    observers=[RTVIObserver(rtvi)],
)
```

**What This Gives You:**
- âœ… Standard client-server protocol
- âœ… Works with official RTVI clients
- âœ… Built-in metrics/monitoring
- âœ… Event system for UI updates

---

## Complete Pipeline Flow

### V3 Official Flow

```
1. User Opens Browser
   â””â”€> Connects to http://localhost:7860/client

2. WebRTC Connection Established
   â””â”€> Daily.co handles ICE/STUN/TURN
   â””â”€> Fires: on_client_connected event

3. Event Handler Triggered
   â””â”€> Queue greeting: LLMRunFrame()
   â””â”€> LLM generates greeting
   â””â”€> Greeting sent to browser

4. User Starts Speaking
   â””â”€> Audio â†’ Daily Transport â†’ Pipeline

5. Pipeline Processing
   [AudioRawFrame]
       â†“
   Silero VAD (detects speech)
       â†“
   Deepgram STT (speech â†’ text)
       â†“
   [TextFrame: "I have 5 years experience"]
       â†“
   RTVI Processor (protocol handling)
       â†“
   Context Aggregator User (auto-add to context)
       â†“
   Interview Processor (track Q&A)
       â†“
   Azure OpenAI LLM (generate response)
       â†“
   [TextFrame: "Great! Tell me about..."]
       â†“
   gTTS Processor (text â†’ audio)
       â†“
   [AudioRawFrame]
       â†“
   Transport Output (back to browser)
       â†“
   Context Aggregator Assistant (auto-save response)

6. Browser Plays Response
   â””â”€> User hears AI speaking
   â””â”€> Cycle repeats for next question

7. Interview Complete
   â””â”€> All 5 questions answered
   â””â”€> Summary generated
   â””â”€> Sent to browser

8. User Disconnects
   â””â”€> Fires: on_client_disconnected
   â””â”€> task.cancel() cleans up
   â””â”€> Resources released
```

---

## Why This Matters

### For Development

**Official patterns mean:**
- ğŸ“š **Documentation matches your code** - No guessing how to adapt examples
- ğŸ› **Easier debugging** - Community can help because they recognize the pattern
- ğŸ”„ **Quick updates** - When Pipecat improves, you benefit immediately
- ğŸ“¦ **Composable** - Mix and match official services/processors

### For Production

**Official patterns mean:**
- ğŸš€ **Pipecat Cloud compatible** - Deploy with `pipecat cloud deploy`
- ğŸ“Š **Built-in monitoring** - Metrics and observability included
- ğŸ” **Secrets management** - `pipecat cloud secrets` works out of the box
- ğŸŒ **Scaling built-in** - Set `min_agents` in config, done

### For Learning

**Official patterns mean:**
- âœ… **Follow Pipecat tutorials** - They use the same structure
- âœ… **Browse examples** - 30+ examples all use this pattern
- âœ… **Get help easily** - Discord/GitHub recognize your code
- âœ… **Future-proof** - Won't break when Pipecat evolves

---

## Key Files Explained

### `bot.py` - Main Bot

```python
# The THREE key functions:

1. bot(runner_args)
   - Entry point
   - Creates transport
   - Calls run_bot()

2. run_bot(transport, runner_args)
   - Creates services (STT, LLM, TTS)
   - Builds pipeline
   - Sets up event handlers
   - Runs task

3. main()  # if __name__ == "__main__"
   - Official Pipecat runner
   - Handles CLI args, signals, etc.
```

### `requirements.txt` - Dependencies

```txt
pipecat-ai[daily,azure,deepgram,silero]
- daily: WebRTC transport
- azure: Azure OpenAI service
- deepgram: STT service
- silero: VAD analyzer

gTTS: Natural voice (our custom choice)
python-dotenv: Environment variables
loguru: Better logging
```

### `.env` - Configuration

```ini
AZURE_OPENAI_*     # LLM service
DEEPGRAM_API_KEY   # STT service
DAILY_API_KEY      # WebRTC transport
```

---

## Extending V3

### Add New Processor

```python
class TimerProcessor(FrameProcessor):
    """Add 30-second timer per answer"""
    
    async def process_frame(self, frame, direction):
        await super().process_frame(frame, direction)
        
        if isinstance(frame, TextFrame):
            # Start timer logic
            pass
        
        await self.push_frame(frame, direction)

# Add to pipeline
pipeline = Pipeline([
    transport.input(),
    rtvi,
    stt,
    context_aggregator.user(),
    interview_processor,
    TimerProcessor(),  # â† Your new processor!
    llm,
    tts,
    transport.output(),
    context_aggregator.assistant(),
])
```

### Swap TTS Service

```python
# Use Deepgram TTS instead of gTTS
from pipecat.services.deepgram import DeepgramTTSService

tts = DeepgramTTSService(
    api_key=deepgram_api_key,
    voice="aura-asteria-en"  # Natural voice
)

# Add to pipeline - no other changes needed!
```

### Add Custom Event

```python
@transport.event_handler("on_custom_event")
async def on_custom_event(transport, data):
    logger.info(f"Custom event: {data}")
    # Your logic here
```

---

## Deployment to Pipecat Cloud

When ready for production:

### 1. Create Dockerfile

```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY bot.py .
CMD ["python", "bot.py"]
```

### 2. Create `pcc-deploy.toml`

```toml
agent_name = "interview-bot-v3"
image = "your-dockerhub/interview-bot:v3"
secret_set = "interview-secrets"

[scaling]
    min_agents = 1  # Keep 1 ready at all times
```

### 3. Deploy

```bash
# Upload secrets
pipecat cloud secrets set interview-secrets --file .env

# Build and push
pipecat cloud docker build-push

# Deploy
pipecat cloud deploy
```

Done! Your bot is live worldwide. ğŸŒ

---

## Summary

**V3 is not just "using Pipecat"â€”it's using Pipecat THE RIGHT WAY.**

By following official patterns, you get:
- âœ… Code that matches documentation
- âœ… Production-ready from day 1
- âœ… Easy to extend and maintain
- âœ… Community support
- âœ… Cloud deployment ready
- âœ… Future-proof architecture

**Start with V3 for any new project!** ğŸš€

---

**Learn More:**
- [Official Quickstart](https://docs.pipecat.ai/getting-started/quickstart)
- [Pipecat Examples](https://github.com/pipecat-ai/pipecat-examples)
- [RTVI Protocol](https://docs.pipecat.ai/client/rtvi-standard)
- [Pipecat Cloud](https://docs.pipecat.ai/deployment/pipecat-cloud/introduction)
