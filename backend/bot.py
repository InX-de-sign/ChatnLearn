"""
Pipecat bot for AI interview assistant
Handles real-time voice conversation with video avatar
"""
import os
import asyncio
from pipecat.pipeline.pipeline import Pipeline
from pipecat.pipeline.runner import PipelineRunner
from pipecat.pipeline.task import PipelineParams, PipelineTask
from pipecat.services.openai import OpenAILLMService
from pipecat.services.deepgram import DeepgramSTTService, DeepgramTTSService
from pipecat.transports.services.daily import DailyParams, DailyTransport
from pipecat.vad.silero import SileroVADAnalyzer
from pipecat.processors.aggregators.openai_llm_context import OpenAILLMContext
from pipecat.frames.frames import EndFrame, LLMMessagesFrame
from loguru import logger
from dotenv import load_dotenv

# Load environment variables
load_dotenv()


async def run_bot(room_url: str, room_name: str):
    """
    Run the Pipecat bot in a Daily.co room
    
    Args:
        room_url: The Daily.co room URL
        room_name: The room name identifier
    """
    
    logger.info(f"Starting bot for room: {room_name}")
    
    # Get API keys from environment
    daily_api_key = os.getenv("DAILY_API_KEY")
    openai_api_key = os.getenv("OPENAI_API_KEY")
    deepgram_api_key = os.getenv("DEEPGRAM_API_KEY")
    
    if not all([daily_api_key, openai_api_key, deepgram_api_key]):
        logger.error("Missing required API keys")
        return
    
    # Configure Daily transport for WebRTC video
    transport = DailyTransport(
        room_url,
        None,  # Token will be generated by Daily
        "Interview AI Assistant",
        DailyParams(
            api_key=daily_api_key,
            audio_in_enabled=True,
            audio_out_enabled=True,
            camera_out_enabled=True,
            vad_enabled=True,
            vad_analyzer=SileroVADAnalyzer(),
            transcription_enabled=True,
        )
    )
    
    # Configure STT (Speech-to-Text) using Deepgram
    stt = DeepgramSTTService(
        api_key=deepgram_api_key,
        model="nova-2",
        language="en-US",
    )
    
    # Configure TTS (Text-to-Speech) using Deepgram
    tts = DeepgramTTSService(
        api_key=deepgram_api_key,
        voice="aura-helios-en",  # Professional male voice
    )
    
    # Configure LLM using OpenAI
    llm = OpenAILLMService(
        api_key=openai_api_key,
        model="gpt-4o",  # Using GPT-4 for better conversation quality
    )
    
    # System prompt for interview assistant
    system_prompt = """You are an AI interview coach helping users practice for job interviews. 
    
Your role is to:
1. Ask relevant interview questions based on the job role the user mentions
2. Provide constructive feedback on their answers
3. Help them improve their communication skills
4. Be encouraging and supportive while being honest about areas for improvement
5. Ask follow-up questions to help them think deeper

Start by asking what role they're interviewing for, then conduct a realistic interview practice session.
Keep your responses concise and natural, as if you're in a real interview."""
    
    # Initialize conversation context
    context = OpenAILLMContext(
        messages=[
            {
                "role": "system",
                "content": system_prompt
            }
        ]
    )
    
    # Set initial context
    context_aggregator = llm.create_context_aggregator(context)
    
    # Create pipeline
    pipeline = Pipeline([
        transport.input(),   # Receive audio/video from user
        stt,                 # Convert speech to text
        context_aggregator.user(),  # Add user message to context
        llm,                 # Generate AI response
        tts,                 # Convert text to speech
        transport.output(),  # Send audio/video to user
        context_aggregator.assistant(),  # Add assistant message to context
    ])
    
    # Create task
    task = PipelineTask(
        pipeline,
        PipelineParams(
            allow_interruptions=True,
            enable_metrics=True,
            enable_usage_metrics=True,
        )
    )
    
    # Create runner
    runner = PipelineRunner()
    
    # Queue initial greeting
    await task.queue_frames([
        LLMMessagesFrame([
            {
                "role": "system",
                "content": system_prompt
            },
            {
                "role": "user",
                "content": "Hello! I'm ready to practice my interview."
            }
        ])
    ])
    
    try:
        # Run the bot
        await runner.run(task)
    except Exception as e:
        logger.error(f"Error running bot: {e}")
    finally:
        logger.info(f"Bot session ended for room: {room_name}")


if __name__ == "__main__":
    # For testing
    import sys
    if len(sys.argv) > 1:
        room_url = sys.argv[1]
        room_name = sys.argv[2] if len(sys.argv) > 2 else "test-room"
        asyncio.run(run_bot(room_url, room_name))
    else:
        print("Usage: python bot.py <room_url> [room_name]")
